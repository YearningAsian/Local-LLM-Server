{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.26666666666666666,
  "eval_steps": 500,
  "global_step": 100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0026666666666666666,
      "grad_norm": NaN,
      "learning_rate": 0.0,
      "loss": 7.7759,
      "step": 1
    },
    {
      "epoch": 0.005333333333333333,
      "grad_norm": NaN,
      "learning_rate": 0.0,
      "loss": 9.0737,
      "step": 2
    },
    {
      "epoch": 0.008,
      "grad_norm": NaN,
      "learning_rate": 0.0,
      "loss": 8.526,
      "step": 3
    },
    {
      "epoch": 0.010666666666666666,
      "grad_norm": NaN,
      "learning_rate": 0.0,
      "loss": 9.0772,
      "step": 4
    },
    {
      "epoch": 0.013333333333333334,
      "grad_norm": 51.082305908203125,
      "learning_rate": 0.0,
      "loss": 8.3634,
      "step": 5
    },
    {
      "epoch": 0.016,
      "grad_norm": 47.764610290527344,
      "learning_rate": 5e-06,
      "loss": 8.5543,
      "step": 6
    },
    {
      "epoch": 0.018666666666666668,
      "grad_norm": 57.49942398071289,
      "learning_rate": 1e-05,
      "loss": 8.1137,
      "step": 7
    },
    {
      "epoch": 0.021333333333333333,
      "grad_norm": 54.74522018432617,
      "learning_rate": 1.5e-05,
      "loss": 8.4111,
      "step": 8
    },
    {
      "epoch": 0.024,
      "grad_norm": 52.5634765625,
      "learning_rate": 2e-05,
      "loss": 7.8561,
      "step": 9
    },
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 52.40361404418945,
      "learning_rate": 2.5e-05,
      "loss": 7.1363,
      "step": 10
    },
    {
      "epoch": 0.029333333333333333,
      "grad_norm": 53.93169403076172,
      "learning_rate": 3e-05,
      "loss": 5.5789,
      "step": 11
    },
    {
      "epoch": 0.032,
      "grad_norm": 52.88254928588867,
      "learning_rate": 3.5e-05,
      "loss": 5.2284,
      "step": 12
    },
    {
      "epoch": 0.034666666666666665,
      "grad_norm": 51.42533493041992,
      "learning_rate": 4e-05,
      "loss": 4.8049,
      "step": 13
    },
    {
      "epoch": 0.037333333333333336,
      "grad_norm": 46.43364715576172,
      "learning_rate": 4.5e-05,
      "loss": 3.1787,
      "step": 14
    },
    {
      "epoch": 0.04,
      "grad_norm": 36.66518020629883,
      "learning_rate": 5e-05,
      "loss": 2.0955,
      "step": 15
    },
    {
      "epoch": 0.042666666666666665,
      "grad_norm": 22.331682205200195,
      "learning_rate": 4.9999900766173944e-05,
      "loss": 1.2298,
      "step": 16
    },
    {
      "epoch": 0.04533333333333334,
      "grad_norm": 7.8827643394470215,
      "learning_rate": 4.999960306548357e-05,
      "loss": 0.6459,
      "step": 17
    },
    {
      "epoch": 0.048,
      "grad_norm": 4.632687091827393,
      "learning_rate": 4.999910690029223e-05,
      "loss": 0.5271,
      "step": 18
    },
    {
      "epoch": 0.050666666666666665,
      "grad_norm": 1.1043310165405273,
      "learning_rate": 4.999841227453884e-05,
      "loss": 0.4404,
      "step": 19
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 0.2743087112903595,
      "learning_rate": 4.9997519193737816e-05,
      "loss": 0.4233,
      "step": 20
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.1888124644756317,
      "learning_rate": 4.999642766497909e-05,
      "loss": 0.4153,
      "step": 21
    },
    {
      "epoch": 0.058666666666666666,
      "grad_norm": 0.19830209016799927,
      "learning_rate": 4.999513769692796e-05,
      "loss": 0.3996,
      "step": 22
    },
    {
      "epoch": 0.06133333333333333,
      "grad_norm": 0.20436599850654602,
      "learning_rate": 4.9993649299825116e-05,
      "loss": 0.4188,
      "step": 23
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.1915062814950943,
      "learning_rate": 4.999196248548651e-05,
      "loss": 0.398,
      "step": 24
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 0.1970202773809433,
      "learning_rate": 4.9990077267303254e-05,
      "loss": 0.3827,
      "step": 25
    },
    {
      "epoch": 0.06933333333333333,
      "grad_norm": 0.19634966552257538,
      "learning_rate": 4.998799366024155e-05,
      "loss": 0.4101,
      "step": 26
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.18907730281352997,
      "learning_rate": 4.998571168084254e-05,
      "loss": 0.4236,
      "step": 27
    },
    {
      "epoch": 0.07466666666666667,
      "grad_norm": 0.19899360835552216,
      "learning_rate": 4.998323134722218e-05,
      "loss": 0.4045,
      "step": 28
    },
    {
      "epoch": 0.07733333333333334,
      "grad_norm": 0.18648572266101837,
      "learning_rate": 4.998055267907113e-05,
      "loss": 0.406,
      "step": 29
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.17389751970767975,
      "learning_rate": 4.997767569765452e-05,
      "loss": 0.3888,
      "step": 30
    },
    {
      "epoch": 0.08266666666666667,
      "grad_norm": 0.1840987503528595,
      "learning_rate": 4.997460042581188e-05,
      "loss": 0.3898,
      "step": 31
    },
    {
      "epoch": 0.08533333333333333,
      "grad_norm": 0.18158365786075592,
      "learning_rate": 4.997132688795689e-05,
      "loss": 0.3983,
      "step": 32
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.1771593689918518,
      "learning_rate": 4.9967855110077187e-05,
      "loss": 0.3843,
      "step": 33
    },
    {
      "epoch": 0.09066666666666667,
      "grad_norm": 0.17052587866783142,
      "learning_rate": 4.996418511973422e-05,
      "loss": 0.3848,
      "step": 34
    },
    {
      "epoch": 0.09333333333333334,
      "grad_norm": 0.16304469108581543,
      "learning_rate": 4.9960316946062944e-05,
      "loss": 0.3737,
      "step": 35
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.16992373764514923,
      "learning_rate": 4.995625061977167e-05,
      "loss": 0.3902,
      "step": 36
    },
    {
      "epoch": 0.09866666666666667,
      "grad_norm": 0.16202996671199799,
      "learning_rate": 4.995198617314175e-05,
      "loss": 0.3796,
      "step": 37
    },
    {
      "epoch": 0.10133333333333333,
      "grad_norm": 0.16898764669895172,
      "learning_rate": 4.994752364002737e-05,
      "loss": 0.3891,
      "step": 38
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.1742773801088333,
      "learning_rate": 4.9942863055855295e-05,
      "loss": 0.3897,
      "step": 39
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 0.16546204686164856,
      "learning_rate": 4.993800445762451e-05,
      "loss": 0.3829,
      "step": 40
    },
    {
      "epoch": 0.10933333333333334,
      "grad_norm": 0.1681963950395584,
      "learning_rate": 4.9932947883906e-05,
      "loss": 0.3859,
      "step": 41
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.17044106125831604,
      "learning_rate": 4.992769337484243e-05,
      "loss": 0.36,
      "step": 42
    },
    {
      "epoch": 0.11466666666666667,
      "grad_norm": 0.1660912036895752,
      "learning_rate": 4.9922240972147795e-05,
      "loss": 0.3828,
      "step": 43
    },
    {
      "epoch": 0.11733333333333333,
      "grad_norm": 0.15614306926727295,
      "learning_rate": 4.9916590719107115e-05,
      "loss": 0.3686,
      "step": 44
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.16693836450576782,
      "learning_rate": 4.991074266057609e-05,
      "loss": 0.3741,
      "step": 45
    },
    {
      "epoch": 0.12266666666666666,
      "grad_norm": 0.16783669590950012,
      "learning_rate": 4.9904696842980734e-05,
      "loss": 0.3656,
      "step": 46
    },
    {
      "epoch": 0.12533333333333332,
      "grad_norm": 0.1657777577638626,
      "learning_rate": 4.989845331431703e-05,
      "loss": 0.3736,
      "step": 47
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.16707350313663483,
      "learning_rate": 4.989201212415051e-05,
      "loss": 0.363,
      "step": 48
    },
    {
      "epoch": 0.13066666666666665,
      "grad_norm": 0.16765044629573822,
      "learning_rate": 4.988537332361588e-05,
      "loss": 0.3629,
      "step": 49
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 0.16799573600292206,
      "learning_rate": 4.9878536965416636e-05,
      "loss": 0.3447,
      "step": 50
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.17207080125808716,
      "learning_rate": 4.987150310382461e-05,
      "loss": 0.3372,
      "step": 51
    },
    {
      "epoch": 0.13866666666666666,
      "grad_norm": 0.1607048511505127,
      "learning_rate": 4.9864271794679566e-05,
      "loss": 0.3314,
      "step": 52
    },
    {
      "epoch": 0.14133333333333334,
      "grad_norm": 0.15438273549079895,
      "learning_rate": 4.985684309538875e-05,
      "loss": 0.3167,
      "step": 53
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.1676623523235321,
      "learning_rate": 4.984921706492641e-05,
      "loss": 0.3237,
      "step": 54
    },
    {
      "epoch": 0.14666666666666667,
      "grad_norm": 0.1701117753982544,
      "learning_rate": 4.984139376383336e-05,
      "loss": 0.3332,
      "step": 55
    },
    {
      "epoch": 0.14933333333333335,
      "grad_norm": 0.172136127948761,
      "learning_rate": 4.98333732542165e-05,
      "loss": 0.3284,
      "step": 56
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.16680166125297546,
      "learning_rate": 4.982515559974829e-05,
      "loss": 0.2997,
      "step": 57
    },
    {
      "epoch": 0.15466666666666667,
      "grad_norm": 0.17760148644447327,
      "learning_rate": 4.9816740865666266e-05,
      "loss": 0.3142,
      "step": 58
    },
    {
      "epoch": 0.15733333333333333,
      "grad_norm": 0.18037471175193787,
      "learning_rate": 4.980812911877254e-05,
      "loss": 0.3096,
      "step": 59
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.16574032604694366,
      "learning_rate": 4.979932042743324e-05,
      "loss": 0.3005,
      "step": 60
    },
    {
      "epoch": 0.16266666666666665,
      "grad_norm": 0.1795729696750641,
      "learning_rate": 4.979031486157797e-05,
      "loss": 0.3087,
      "step": 61
    },
    {
      "epoch": 0.16533333333333333,
      "grad_norm": 0.17407357692718506,
      "learning_rate": 4.9781112492699275e-05,
      "loss": 0.2809,
      "step": 62
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.18515099585056305,
      "learning_rate": 4.977171339385206e-05,
      "loss": 0.3042,
      "step": 63
    },
    {
      "epoch": 0.17066666666666666,
      "grad_norm": 0.1834423542022705,
      "learning_rate": 4.9762117639653006e-05,
      "loss": 0.2984,
      "step": 64
    },
    {
      "epoch": 0.17333333333333334,
      "grad_norm": 0.18350917100906372,
      "learning_rate": 4.975232530627998e-05,
      "loss": 0.2728,
      "step": 65
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.19506490230560303,
      "learning_rate": 4.974233647147144e-05,
      "loss": 0.2783,
      "step": 66
    },
    {
      "epoch": 0.17866666666666667,
      "grad_norm": 0.19358588755130768,
      "learning_rate": 4.9732151214525816e-05,
      "loss": 0.2699,
      "step": 67
    },
    {
      "epoch": 0.18133333333333335,
      "grad_norm": 0.19068734347820282,
      "learning_rate": 4.9721769616300865e-05,
      "loss": 0.2605,
      "step": 68
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.2008601278066635,
      "learning_rate": 4.971119175921305e-05,
      "loss": 0.2709,
      "step": 69
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 0.20324979722499847,
      "learning_rate": 4.970041772723685e-05,
      "loss": 0.2623,
      "step": 70
    },
    {
      "epoch": 0.18933333333333333,
      "grad_norm": 0.20107844471931458,
      "learning_rate": 4.968944760590416e-05,
      "loss": 0.2566,
      "step": 71
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.2080293893814087,
      "learning_rate": 4.967828148230354e-05,
      "loss": 0.2364,
      "step": 72
    },
    {
      "epoch": 0.19466666666666665,
      "grad_norm": 0.21074460446834564,
      "learning_rate": 4.966691944507956e-05,
      "loss": 0.2306,
      "step": 73
    },
    {
      "epoch": 0.19733333333333333,
      "grad_norm": 0.2277536690235138,
      "learning_rate": 4.9655361584432106e-05,
      "loss": 0.2429,
      "step": 74
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.2176368683576584,
      "learning_rate": 4.964360799211562e-05,
      "loss": 0.2195,
      "step": 75
    },
    {
      "epoch": 0.20266666666666666,
      "grad_norm": 0.2541230320930481,
      "learning_rate": 4.963165876143844e-05,
      "loss": 0.2359,
      "step": 76
    },
    {
      "epoch": 0.20533333333333334,
      "grad_norm": 0.23314841091632843,
      "learning_rate": 4.9619513987261966e-05,
      "loss": 0.2038,
      "step": 77
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.24312271177768707,
      "learning_rate": 4.960717376600002e-05,
      "loss": 0.2186,
      "step": 78
    },
    {
      "epoch": 0.21066666666666667,
      "grad_norm": 0.24537144601345062,
      "learning_rate": 4.959463819561797e-05,
      "loss": 0.2025,
      "step": 79
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 0.23766019940376282,
      "learning_rate": 4.9581907375632034e-05,
      "loss": 0.204,
      "step": 80
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.23393729329109192,
      "learning_rate": 4.956898140710845e-05,
      "loss": 0.1824,
      "step": 81
    },
    {
      "epoch": 0.21866666666666668,
      "grad_norm": 0.23728148639202118,
      "learning_rate": 4.9555860392662683e-05,
      "loss": 0.1861,
      "step": 82
    },
    {
      "epoch": 0.22133333333333333,
      "grad_norm": 0.24238763749599457,
      "learning_rate": 4.954254443645861e-05,
      "loss": 0.1791,
      "step": 83
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.229088693857193,
      "learning_rate": 4.952903364420769e-05,
      "loss": 0.1643,
      "step": 84
    },
    {
      "epoch": 0.22666666666666666,
      "grad_norm": 0.2592610716819763,
      "learning_rate": 4.951532812316814e-05,
      "loss": 0.1666,
      "step": 85
    },
    {
      "epoch": 0.22933333333333333,
      "grad_norm": 0.2156154066324234,
      "learning_rate": 4.9501427982144054e-05,
      "loss": 0.1573,
      "step": 86
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.2765517234802246,
      "learning_rate": 4.948733333148456e-05,
      "loss": 0.1838,
      "step": 87
    },
    {
      "epoch": 0.23466666666666666,
      "grad_norm": 0.24803707003593445,
      "learning_rate": 4.947304428308298e-05,
      "loss": 0.1585,
      "step": 88
    },
    {
      "epoch": 0.23733333333333334,
      "grad_norm": 0.23669448494911194,
      "learning_rate": 4.945856095037583e-05,
      "loss": 0.1645,
      "step": 89
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.29903361201286316,
      "learning_rate": 4.944388344834205e-05,
      "loss": 0.1596,
      "step": 90
    },
    {
      "epoch": 0.24266666666666667,
      "grad_norm": 0.2747502624988556,
      "learning_rate": 4.9429011893502016e-05,
      "loss": 0.1527,
      "step": 91
    },
    {
      "epoch": 0.24533333333333332,
      "grad_norm": 0.24979954957962036,
      "learning_rate": 4.941394640391662e-05,
      "loss": 0.1421,
      "step": 92
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.25391021370887756,
      "learning_rate": 4.939868709918637e-05,
      "loss": 0.1473,
      "step": 93
    },
    {
      "epoch": 0.25066666666666665,
      "grad_norm": 0.25062036514282227,
      "learning_rate": 4.9383234100450394e-05,
      "loss": 0.1447,
      "step": 94
    },
    {
      "epoch": 0.25333333333333335,
      "grad_norm": 0.24118223786354065,
      "learning_rate": 4.9367587530385505e-05,
      "loss": 0.1379,
      "step": 95
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.2311708927154541,
      "learning_rate": 4.9351747513205234e-05,
      "loss": 0.1399,
      "step": 96
    },
    {
      "epoch": 0.25866666666666666,
      "grad_norm": 0.24835579097270966,
      "learning_rate": 4.933571417465881e-05,
      "loss": 0.1456,
      "step": 97
    },
    {
      "epoch": 0.2613333333333333,
      "grad_norm": 0.2297261357307434,
      "learning_rate": 4.931948764203019e-05,
      "loss": 0.1165,
      "step": 98
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.25022855401039124,
      "learning_rate": 4.930306804413707e-05,
      "loss": 0.1015,
      "step": 99
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.23194670677185059,
      "learning_rate": 4.9286455511329796e-05,
      "loss": 0.1115,
      "step": 100
    }
  ],
  "logging_steps": 1,
  "max_steps": 1125,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.38434129854464e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
